{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Scene Segmentation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Jiaolong Xu (GitHub ID: [Jiaolong](https://github.com/Jiaolong))"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Multi-class scene segmentation (or pixel labeling) aims to label every pixel in an image with one of a\n",
      "number of classes (e.g., grass, sky, water, etc). Since classifying every pixel can be computationally\n",
      "expensive, many state-of-the-art methods first over-segment the image into superpixels (or small coherent\n",
      "regions) and classify each region."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load scene segmentation dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We define 'Example' class to store the superpixel features, labels, adjacent matrix, etc of each example."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Example:\n",
      "    \"\"\" Example class.\n",
      "\n",
      "        Parameters:\n",
      "            id: id of the example\n",
      "            im: image data\n",
      "            labels: ground truth pixel labels\n",
      "            segs: a matrix of superpixel segmentations\n",
      "            feat: feature of each superpixel\n",
      "            segLabels: the semantic label of each superpixel segmentation\n",
      "            adj: adjacent matrix defining pairwise superpixels\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, id, im, labels, segs, feat, segLabels, adj):\n",
      "        self.id = id\n",
      "        self.im = im\n",
      "        self.labels = labels\n",
      "        self.segs = segs\n",
      "        self.feature = feat\n",
      "        self.segLabels = segLabels\n",
      "        self.adj = adj"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The 'load_stanford_bg_data' will read the examples from matlab file. \n",
      "\n",
      "We use the [Stanford background dataset](http://dags.stanford.edu/projects/scenedataset.html) for scene segmentation, and the data file in this experiment is obtained from [1]. The data file includes:\n",
      "- original images\n",
      "- superpixels/ oversegmentation\n",
      "- features for each superpixel\n",
      "- ground truth labels for pixels and superpixels\n",
      "- superpixel adjacency matrix \n",
      "\n",
      "We briefly introduce the pre-process of the scene segmentation data in the following, more details can be found in [3, 4].\n",
      "- First, the image is over-segmented into superpixels (or small coherent\n",
      "regions). Free online code such as that provided by [Greg Mori](http://www.cs.sfu.ca/~mori/research/superpixels/code/) or [Pedro Felzenszwalb](http://people.cs.uchicago.edu/~pff/segment/) can be used for this purpose.\n",
      "\n",
      "- Once the image regions/superpixels have been defined, appearance (color and texture),\n",
      "geometry and location based features can be extract for each superpixel. During this step the groundtruth label for each superpixel is also extract. This is done by finding the maximum occurring pixel label within each superpixel.\n",
      "- Performance can be greatly improved if learn a boosted classifier for each class instead of using the raw\n",
      "appearance, geometry and location features described above. A one-versus-all\n",
      "classifier for each groundtruth label is applied using the cached superpixel features and labels from the previous\n",
      "step.\n",
      "- Once the classifiers are learned new feature can be created, which\n",
      "contain the output score for each of the learned classifiers on each superpixel in an image. Bias terms\n",
      "are also included so that these features files can be used directly by the CRF models."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_stanford_bg_data(fname, binary = False):\n",
      "    \"\"\" Load stanford back ground dataset.\n",
      "\n",
      "        Args:\n",
      "            fname: file name\n",
      "            binary: if true, use binary label, i.e., foreground/background\n",
      "                    else use multiclass label\n",
      "    \"\"\"\n",
      "\n",
      "    import scipy.io\n",
      "    mat = scipy.io.loadmat(fname)\n",
      "    all_data = mat['allData']\n",
      "\n",
      "    example_list = []\n",
      "    num_status = 0\n",
      "\n",
      "    for i in range(all_data.shape[1]):\n",
      "        im = all_data[0,i]['img'][0][0]\n",
      "        labels = all_data[0,i]['labels'][0][0]\n",
      "        segs2 = all_data[0,i]['segs2'][0][0]\n",
      "        feat2 = all_data[0,i]['feat2'][0][0]\n",
      "        segLabels = all_data[0,i]['segLabels'][0][0]\n",
      "        segLabels = np.transpose(segLabels)[0].astype(np.int32)\n",
      "        adj = all_data[0,i]['adj'][0][0]\n",
      "\n",
      "        labels = labels - 1\n",
      "        segs2 = segs2 - 1\n",
      "        segLabels = segLabels - 1\n",
      "        \n",
      "        if min(segLabels) < 0 or max(segLabels) > 7:\n",
      "            print '\\n label is not valid!'\n",
      "            continue\n",
      "            \n",
      "        if binary == True:\n",
      "            labels[labels<7] = 0\n",
      "            labels[labels==7] = 1\n",
      "            segLabels[segLabels<7] = 0 # background\n",
      "            segLabels[segLabels==7] = 1 # foreground\n",
      "            \n",
      "        num_status = max(num_status, max(segLabels))\n",
      "        example = Example(i, im, labels, segs2, feat2, segLabels, adj)\n",
      "        example_list.append(example)\n",
      "\n",
      "    num_status = num_status + 1\n",
      "    dim_feat = 0\n",
      "\n",
      "    if len(example_list) > 0:\n",
      "        dim_feat = example_list[0].feature.shape[1]\n",
      "\n",
      "    return example_list, num_status, dim_feat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this experiment, the $119$ dimentional superpixel feature is used as unary feature. We add a binary choise to allow foreground/background segmentation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# By setting Binary=True, we create a foreground vs background segmentation demo\n",
      "# otherwise, we perform multiclass scene segmentation\n",
      "Binary = False\n",
      "\n",
      "# data file name\n",
      "fname = '/home/jiaolong/Work/Code_Git/data-shogun/scene_segmentation/iccv09-1-allNeighborPairs_train_tiny.mat'\n",
      "#fname = '/home/jiaolong/Work/Code_Git/data-shogun/scene_segmentation/iccv09-eval.mat'\n",
      "\n",
      "# load data\n",
      "example_list, num_status, dim_feat = load_stanford_bg_data(fname, Binary)\n",
      "#example_list = example_list[:5]\n",
      "    \n",
      "print '\\nNumber of examples: %d' % len(example_list)\n",
      "print '\\nNumber of scene classes: %d' % num_status\n",
      "print '\\nDimention of the unary feature: %d' % dim_feat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we creat a function to visualize our examples, including original RGB image, pixel labels, over segmentation and super-pixel labels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_example(example, binary = False):\n",
      "    \"\"\" Plot example.\"\"\"\n",
      "\n",
      "    im = example.im\n",
      "    labels = example.labels\n",
      "    segLabels = example.segLabels\n",
      "    segs = example.segs\n",
      "\n",
      "    im_gt   = np.zeros(segs.shape)\n",
      "    for v in range(segLabels.shape[0]):\n",
      "        im_gt[segs == v] = segLabels[v]\n",
      "        \n",
      "    s = 1\n",
      "    if binary:\n",
      "        s = 255\n",
      "        \n",
      "    fig, plots = plt.subplots(1, 4, figsize=(18, 6))\n",
      "    plots[0].imshow(im)\n",
      "    plots[0].set_title('RGB image')\n",
      "    plots[1].matshow(labels*s)\n",
      "    plots[1].set_title('pixel labels')\n",
      "    plots[2].matshow(segs)\n",
      "    plots[2].set_title('over segmentations')\n",
      "    plots[3].matshow(im_gt*s)\n",
      "    plots[3].set_title('super pixel labels')\n",
      "\n",
      "    for p in plots:\n",
      "        p.set_xticks(())\n",
      "        p.set_yticks(())\n",
      "\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot an example\n",
      "plot_example(example_list[0], Binary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Build Factor Graph Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import Factor, TableFactorType, FactorGraph\n",
      "from modshogun import FactorGraphObservation, FactorGraphLabels, FactorGraphFeatures\n",
      "from modshogun import FactorGraphModel, LP_RELAXATION, GRAPH_CUT\n",
      "from modshogun import MAPInference"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# inference algorithm\n",
      "infer_alg = LP_RELAXATION\n",
      "#infer_alg = GRAPH_CUT\n",
      "\n",
      "if infer_alg == GRAPH_CUT and Binary == False:\n",
      "    print 'Current graph cuts inference can only handle binary labels'\n",
      "    raise"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For scene segmentaion CRF model, we define two types of factors:\n",
      "- unary factor: the unary factor type is used to define unary potentials that captures the the appearance likelyhood of each super-pixel. We use $119$ dimentional unary feature in this experiment. As we have $8$ classes, the unary parameter is $8 \\times 119$.\n",
      "- pairwise factor: the pairwise factor type is used to define pairwise potentials between each pair of super pixels. There features of the pairwise factors are constant $1$ and there are no additional edge features. For the pairwise factors, there are  $8 \\times 8$ parameters.\n",
      "\n",
      "Putting all parameters together, the global parameter vector $\\mathbf{w}$ has length $1016$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def define_factor_type(num_status, dim_feat):\n",
      "    \"\"\" Define factor type.\n",
      "\n",
      "        For scene segmentation, there are\n",
      "        only unary and pairwise factor types.\n",
      "\n",
      "        Args:\n",
      "            num_status: number of status\n",
      "            dim_feat: dimention of the unary node feature\n",
      "\n",
      "        Returns:\n",
      "            ftype_unary: unary factor type\n",
      "            ftype_pair: pairwise factor type\n",
      "    \"\"\"\n",
      "\n",
      "    # unary, type id = 0\n",
      "    cards_u = np.array([num_status], np.int32) # cardinalities\n",
      "    w_u = np.zeros(num_status*dim_feat, np.float64)\n",
      "    ftype_unary = TableFactorType(0, cards_u, w_u)\n",
      "\n",
      "    # pairwise, type id = 1\n",
      "    cards_p = np.array([num_status, num_status], np.int32)\n",
      "    w_p = np.zeros(num_status*num_status, np.float64)\n",
      "    ftype_pair = TableFactorType(1, cards_p, w_p)\n",
      "\n",
      "    return ftype_unary, ftype_pair"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define factor type\n",
      "ftype_unary, ftype_pair = define_factor_type(num_status, dim_feat)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As we have got adjacent matrix from the dataset, we can easily compute the indeces of each pairwise super pixels."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_edge_list(adj, direct=False):\n",
      "    \"\"\" Get edge list from adjacent matrix.\n",
      "\n",
      "        Args:\n",
      "            adj: adjacent matrix\n",
      "            direct: True for directed graph\n",
      "\n",
      "        Return:\n",
      "            edge list\n",
      "    \"\"\"\n",
      "\n",
      "    if not  direct:\n",
      "        for i in range(adj.shape[0]):\n",
      "            for j in range(i+1, adj.shape[1]):\n",
      "                adj[j][i] = 0\n",
      "\n",
      "    xs, ys = (adj>0).nonzero()\n",
      "\n",
      "    return np.column_stack([xs, ys])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The features and labels from the above examples will be converted to the fatcor graph features and labels which will be used to build the factor graph model. Each example (or image) corresponds to a factor graph, where each super pixel defines a unary node and each pair of connected super pixels defines a pairwise factor. All unary factors are the same type, i.e., they share the same unary parameters and all pairwise factors share the same pairwise parameters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prepare_factor_graph_model(example_list, num_status, dim_feat, ftype_unary, ftype_pair):\n",
      "    \"\"\" Prepare factor graph model data.\n",
      "\n",
      "        Args:\n",
      "            example_list: the examples\n",
      "            num_status: number of status\n",
      "            dim_feat: dimention of the unary features\n",
      "    \"\"\"\n",
      "\n",
      "    num_samples = len(example_list)\n",
      "    # get factor type definitions\n",
      "    #ftype_unary, ftype_pair = define_factor_type(num_status, dim_feat)\n",
      "    # Initialize factor graph features and labels\n",
      "    feats_fg = FactorGraphFeatures(num_samples)\n",
      "    labels_fg = FactorGraphLabels(num_samples)\n",
      "\n",
      "    # Interate over all the examples\n",
      "    for i in range(num_samples):\n",
      "        example = example_list[i]\n",
      "        feats = example.feature\n",
      "        num_var = feats.shape[0]\n",
      "        dim_feat = feats.shape[1]\n",
      "\n",
      "        # get edge list from adjacent matrix\n",
      "        edge_list = get_edge_list(example.adj)\n",
      "        # print edge_list\n",
      "\n",
      "        # Initialize factor graph\n",
      "        cards = np.array([num_status]*num_var, np.int32) # cardinalities\n",
      "        fg = FactorGraph(cards)\n",
      "\n",
      "        # add unary\n",
      "        for u in range(num_var):\n",
      "            data_u = np.array(feats[u,:], np.float64)\n",
      "            inds_u = np.array([u], np.int32)\n",
      "            factor_u = Factor(ftype_unary, inds_u, data_u)\n",
      "            fg.add_factor(factor_u)\n",
      "        \n",
      "        # add pairwise\n",
      "        for p in range(edge_list.shape[0]):\n",
      "            data_p = np.array([1.0], np.float64)\n",
      "            inds_p = np.array(edge_list[p,:], np.int32)\n",
      "            factor_p = Factor(ftype_pair, inds_p, data_p)\n",
      "            fg.add_factor(factor_p)\n",
      "        \n",
      "        # add factor graph feature\n",
      "        feats_fg.add_sample(fg)\n",
      "        # add factor graph label\n",
      "        labels = example.segLabels.astype(np.int32)\n",
      "        assert(labels.shape[0] == num_var)\n",
      "        loss_weight = np.array([1.0/num_var]*num_var)\n",
      "        f_obs = FactorGraphObservation(labels, loss_weight)\n",
      "        labels_fg.add_label(f_obs)\n",
      "\n",
      "    return feats_fg, labels_fg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we create factor graph model with factor graph features and factor graph factor labels. The factor graph model has a parameter for inference algorithms. The inference algorithm will be used to find the best output, i.e., $\n",
      "\\hat{\\textbf{y}} = \\underset{\\textbf{y} \\in \\mathcal{Y}}{\\operatorname{argmax}} f(\\textbf{x},\\textbf{y}).\n",
      "$\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# prepare features and labels for factor graph model\n",
      "feats_fg, labels_fg = prepare_factor_graph_model(example_list, num_status, dim_feat, ftype_unary, ftype_pair)\n",
      "\n",
      "# create factor graph model\n",
      "model = FactorGraphModel(feats_fg, labels_fg, infer_alg, False)\n",
      "model.add_factor_type(ftype_unary)\n",
      "model.add_factor_type(ftype_pair)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Train CRF model with SOSVM"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have built the factor graph model, now we try to learn the parameters of the model. The parameters can be learned by structured output SVM. In this experiment, we train with BMRM (dual bundle method sosvm). In Shogun, there are several batch solvers and online solvers. We choose a batch dual bundle method solver (<a href=\"http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CDualLibQPBMSOSVM.html\">DualLibQPBMSOSVM</a>) [2]. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import DualLibQPBMSOSVM\n",
      "import time\n",
      "\n",
      "# train with BMRM\n",
      "# create bundle method SOSVM\n",
      "# lambda is set to 1e-2\n",
      "bmrm = DualLibQPBMSOSVM(model, labels_fg, 0.1)\n",
      "\n",
      "bmrm.set_TolAbs(0.1)\n",
      "bmrm.set_verbose(True)\n",
      "bmrm.set_store_train_info(True)\n",
      "    \n",
      "# train\n",
      "t0 = time.time()\n",
      "bmrm.train()\n",
      "t1 = time.time()\n",
      "\n",
      "w_ = bmrm.get_w()\n",
      "\n",
      "print \"BMRM took\", t1 - t0, \"seconds.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluation(labels_pr, labels_gt, model):\n",
      "    \"\"\" Evaluation\n",
      "\n",
      "        Args:\n",
      "            labels_pr: predicted label\n",
      "            labels_gt: ground truth label\n",
      "            model: factor graph model\n",
      "\n",
      "        Returns:\n",
      "            ave_loss: average loss\n",
      "    \"\"\"\n",
      "\n",
      "    num_train_samples = labels_pr.get_num_labels()\n",
      "    acc_loss = 0.0\n",
      "    ave_loss = 0.0\n",
      "    for i in range(num_train_samples):\n",
      "        y_pred = labels_pr.get_label(i)\n",
      "        y_truth = labels_gt.get_label(i)\n",
      "        acc_loss = acc_loss + model.delta_loss(y_truth, y_pred)\n",
      "\n",
      "    ave_loss = acc_loss / num_train_samples\n",
      "\n",
      "    return ave_loss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# training error\n",
      "labels_pr = bmrm.apply()\n",
      "ave_loss = evaluation(labels_pr, labels_fg, model)\n",
      "print('BMRM: Average training error is %.4f' % ave_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_primal_trainError(sosvm, name = 'SGD'):\n",
      "    \"\"\" Plot primal objective values and training errors.\"\"\"\n",
      "    \n",
      "    primal_val = sosvm.get_helper().get_primal_values()\n",
      "    train_err = sosvm.get_helper().get_train_errors()\n",
      "    \n",
      "    fig, plots = plt.subplots(1, 2, figsize=(12,4))\n",
      "    \n",
      "    # primal vs passes\n",
      "    plots[0].plot(range(primal_val.size), primal_val, label=name)\n",
      "    plots[0].set_xlabel('effecitve passes')\n",
      "    plots[0].set_ylabel('primal objective')\n",
      "    plots[0].set_title('whole training progress')\n",
      "    plots[0].legend(loc=1)\n",
      "    plots[0].grid(True)\n",
      "    \n",
      "    # training error vs passes\n",
      "    plots[1].plot(range(train_err.size), train_err, label=name)\n",
      "    plots[1].set_xlabel('effecitve passes')\n",
      "    plots[1].set_ylabel('training error')\n",
      "    plots[1].set_title('effective passes')\n",
      "    plots[1].legend(loc=1)\n",
      "    plots[1].grid(True) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_primal_dual(sosvm, name='BMRM'):\n",
      "    \"\"\" Plot primal and dual objective values.\"\"\"\n",
      "    \n",
      "    fig, plots = plt.subplots(1, 2, figsize=(12,4))\n",
      "    \n",
      "    primal_val = sosvm.get_helper().get_primal_values()\n",
      "    dual_val = sosvm.get_result().get_hist_Fd_vector()\n",
      "\n",
      "    len_iter = min(primal_val.size, dual_val.size)\n",
      "    primal_val = primal_val[1:len_iter]\n",
      "    dual_val = dual_val[1:len_iter]\n",
      "\n",
      "    # plot duality gaps\n",
      "    xs = range(dual_val.size)\n",
      "    plots[0].plot(xs, (primal_val-dual_val), label='duality gap')\n",
      "    plots[0].set_xlabel('iteration')\n",
      "    plots[0].set_ylabel('duality gap')\n",
      "    plots[0].legend(loc=1)\n",
      "    plots[0].set_title('duality gaps');\n",
      "    plots[0].grid(True)\n",
      "\n",
      "    # plot primal and dual values\n",
      "    plots[1].plot(xs, primal_val, label='primal')\n",
      "    plots[1].plot(xs, dual_val, label='dual')\n",
      "    plots[1].set_xlabel('iteration')\n",
      "    plots[1].set_ylabel('objective')\n",
      "    plots[1].legend(loc=1)\n",
      "    plots[1].set_title('primal vs dual');\n",
      "    plots[1].grid(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot primal values and training errors\n",
      "plot_primal_trainError(bmrm, name='BMRM')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot primal and dual objective values\n",
      "plot_primal_dual(bmrm, name='BMRM')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_result(example, y_pred, binary = False):\n",
      "    \"\"\" Plot result.\"\"\"\n",
      "\n",
      "    im = example.im\n",
      "    #labels = example.labels\n",
      "    segs = example.segs\n",
      "    segLabels = example.segLabels\n",
      "\n",
      "    im_pred = np.zeros(segs.shape)\n",
      "    im_gt   = np.zeros(segs.shape)\n",
      "    for v in range(y_pred.shape[0]):\n",
      "        im_gt[segs == v] = segLabels[v]\n",
      "        im_pred[segs == v] = y_pred[v]\n",
      "\n",
      "    s = 1\n",
      "    if binary:\n",
      "        s = 255\n",
      "        \n",
      "    fig, plots = plt.subplots(1, 4, figsize=(18, 6))\n",
      "    plots[0].imshow(im)\n",
      "    plots[0].set_title('RGB image')\n",
      "    plots[1].matshow(im_gt*s)\n",
      "    plots[1].set_title('ground truth labels')\n",
      "    plots[2].matshow(segs)\n",
      "    plots[2].set_title('over segmentations')\n",
      "    plots[3].matshow(im_pred*s)\n",
      "    plots[3].set_title('predicted labels')\n",
      "\n",
      "    for p in plots:\n",
      "        p.set_xticks(())\n",
      "        p.set_yticks(())\n",
      "\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 2\n",
      "\n",
      "y_gt = FactorGraphObservation.obtain_from_generic(labels_fg.get_label(i)).get_data()\n",
      "y_pred = FactorGraphObservation.obtain_from_generic(labels_pr.get_label(i)).get_data()\n",
      "\n",
      "print 'ground truth labels:'\n",
      "print y_gt\n",
      "print 'predicted scene labels:'\n",
      "print y_pred\n",
      "\n",
      "# plot the results\n",
      "plot_result(example_list[i], y_pred, Binary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Train with SGD (Stocastic Subgradient Decent) SOSVM. Now, we use the stochastic subgradient descent (<a href=\"http://www.shogun-toolbox.org/doc/en/latest/classshogun_1_1CStochasticSOSVM.html\">StochasticSOSVM</a>) to compare with the BMRM algorithm shown before."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import StochasticSOSVM\n",
      "\n",
      "# train with Stocastic Gradient Descent\n",
      "sgd = StochasticSOSVM(model, labels_fg, True, True)\n",
      "sgd.set_num_iter(200)\n",
      "sgd.set_lambda(0.0001)\n",
      "#sdg.io.set_loglevel(MSG_DEBUG)\n",
      "\n",
      "# train\n",
      "t0 = time.time()\n",
      "sgd.train()\n",
      "t1 = time.time()\n",
      "w_sgd = sgd.get_w()\n",
      "print \"SGD took\", t1 - t0, \"seconds.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# training error\n",
      "labels_pr = sgd.apply()\n",
      "ave_loss = evaluation(labels_pr, labels_fg, model)\n",
      "print('SGD: Average training error is %.4f' % ave_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot primal values and training errors\n",
      "plot_primal_trainError(sgd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "i = 2\n",
      "\n",
      "y_gt = FactorGraphObservation.obtain_from_generic(labels_fg.get_label(i)).get_data()\n",
      "y_pred = FactorGraphObservation.obtain_from_generic(labels_pr.get_label(i)).get_data()\n",
      "\n",
      "print 'ground truth labels:'\n",
      "print y_gt\n",
      "print 'predicted scene labels:'\n",
      "print y_pred\n",
      "\n",
      "# plot the results\n",
      "plot_result(example_list[i], y_pred, Binary)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reference"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[1] http://www.socher.org/index.php/Main/ParsingNaturalScenesAndNaturalLanguageWithRecursiveNeuralNetworks"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[2] Teo, C.H., Vishwanathan, S.V.N, Smola, A. and Quoc, V.Le, Bundle Methods for Regularized Risk Minimization, JMLR 2010."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[3] S. Gould, R. Fulton, and D. Koller, \"Decomposing a Scene into Geometric and Semantically Consistent Regions.\" In ICCV, 2009. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[4] http://users.cecs.anu.edu.au/~sgould/#software"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}