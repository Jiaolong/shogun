{
 "metadata": {
  "name": "",
  "signature": "sha256:6dfc2a26a2afdf0fb0339062dd1b3d6cf9360757c91b768553e9fbffa9677c5b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Structured Prediction with Graph cuts as Approximate Inference"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Jiaolong Xu (GitHub ID: [Jiaolong](https://github.com/Jiaolong/))"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Introduction"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Graph cuts"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Experiment 1: Max-flow / Min-cut algorithm for general s-t graph optimization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# visulize the s-t graph\n",
      "%matplotlib inline\n",
      "import networkx as nx\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# create a directed graph\n",
      "G = nx.DiGraph()\n",
      "\n",
      "# add variable nodes\n",
      "G.add_nodes_from(['s','v0','v1','v2', 'v3', 'v4', 't'])\n",
      "\n",
      "# positions of the nodes\n",
      "pos = {}\n",
      "pos['s'] = (-2,0)\n",
      "pos['t'] = (2,0)\n",
      "pos['v0'] = (-1,2)\n",
      "pos['v2'] = (0,0)\n",
      "pos['v1'] = (-1,-2)\n",
      "pos['v3'] = (1,2)\n",
      "pos['v4'] = (1,-2)\n",
      "\n",
      "# add weighted edges\n",
      "G.add_edges_from([('s','v0')], weight = 4.0)\n",
      "G.add_edges_from([('s','v1')], weight = 2.0)\n",
      "G.add_edges_from([('s','v2')], weight = 8.0)\n",
      "G.add_edges_from([('v2','t')], weight = 4.0)\n",
      "G.add_edges_from([('v3','t')], weight = 7.0)\n",
      "G.add_edges_from([('v4','t')], weight = 5.0)\n",
      "\n",
      "G.add_edges_from([('v0','v2')], weight = 5.0)\n",
      "G.add_edges_from([('v0','v3')], weight = 2.0)\n",
      "G.add_edges_from([('v1','v2')], weight = 6.0)\n",
      "G.add_edges_from([('v1','v4')], weight = 9.0)\n",
      "G.add_edges_from([('v2','v3')], weight = 1.0)\n",
      "G.add_edges_from([('v2','v4')], weight = 3.0)\n",
      "\n",
      "edge_labels = dict([((u,v,),d['weight']) for u,v,d in G.edges(data=True)])\n",
      "\n",
      "# draw graph\n",
      "fig, ax = plt.subplots(figsize=(8,4))\n",
      "nx.draw_networkx_nodes(G, pos, nodelist=['v0','v1','v2','v3','v4'], node_color='blue', node_size=700,ax=ax)\n",
      "nx.draw_networkx_nodes(G, pos, nodelist=['s'], node_color='green', node_shape='s', node_size=500, ax=ax)\n",
      "nx.draw_networkx_nodes(G, pos, nodelist=['t'], node_color='purple', node_shape='s', node_size=500, ax=ax)\n",
      "nx.draw_networkx_edges(G, pos, alpha = 0.3)\n",
      "nx.draw_networkx_labels(G, pos, font_size = 16)\n",
      "nx.draw_networkx_edge_labels(G, pos, edge_labels = edge_labels)\n",
      "plt.axis('off')\n",
      "plt.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from modshogun import GraphCut\n",
      "\n",
      "num_nodes = 5\n",
      "num_edges = 6\n",
      "\n",
      "g = GraphCut(5, 6)\n",
      "\n",
      "# add termainal-connected edges\n",
      "# i.e., SOURCE->node_i and node_i->SINK\n",
      "g.add_tweights(0, 4, 0)\n",
      "g.add_tweights(1, 2, 0)\n",
      "g.add_tweights(2, 8, 0)\n",
      "g.add_tweights(2, 0, 4)\n",
      "g.add_tweights(3, 0, 7)\n",
      "g.add_tweights(4, 0, 5)\n",
      "\n",
      "# add node to node edges\n",
      "g.add_edge(0, 2, 5, 0)\n",
      "g.add_edge(0, 3, 2, 0)\n",
      "g.add_edge(1, 2, 6, 0)\n",
      "g.add_edge(1, 4, 9, 0)\n",
      "g.add_edge(2, 3, 1, 0)\n",
      "g.add_edge(2, 4, 3, 0)\n",
      "\n",
      "# initialize max-flow algorithm\n",
      "g.init_maxflow()\n",
      "\n",
      "# compute max flow\n",
      "flow = g.compute_maxflow()\n",
      "\n",
      "print(\"Flow = %f\" % flow)\n",
      "\n",
      "# print assignment\n",
      "for i in xrange(num_nodes):\n",
      "    print(\"\\nNode %d = %d\" % (i, g.get_assignment(i)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Experiment 2: Multilabel classification with Synthetic Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import itertools\n",
      "\n",
      "from modshogun import Factor, TableFactorType, FactorGraph\n",
      "from modshogun import FactorGraphObservation, FactorGraphLabels, FactorGraphFeatures\n",
      "from modshogun import FactorGraphModel, TREE_MAX_PROD, GRAPH_CUT, TREE_MAX_PROD, MAPInference\n",
      "\n",
      "from modshogun import StochasticSOSVM\n",
      "from modshogun import DualLibQPBMSOSVM\n",
      "from modshogun import BmrmStatistics\n",
      "\n",
      "import time\n",
      "\n",
      "%matplotlib inline\n",
      "import networkx as nx\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_data(num_samples, len_label, len_feat):\n",
      "    \"\"\" Generate synthetic dataset\n",
      "        \n",
      "        Generate random data following [1]:\n",
      "        Each example has exactly one label on.\n",
      "        Each label has 40 related binary features.\n",
      "        For an example, if label i is on, 4i randomly chosen features are set to 1\n",
      "        \n",
      "        Args:\n",
      "            num_samples: number of samples\n",
      "            len_label: label length (10)\n",
      "            len_feat: feature length (40)\n",
      "        \n",
      "        Returns:\n",
      "            feats: generated feature matrix\n",
      "            labels: generated label matrix\n",
      "    \"\"\"\n",
      "    \n",
      "    labels = np.zeros((num_samples, len_label), np.int32)\n",
      "    feats = np.zeros((num_samples, len_feat), np.int32)\n",
      "    \n",
      "    for k in range(num_samples):\n",
      "        i = k % len_label\n",
      "        labels[k, i] = 1\n",
      "        inds_one = np.random.permutation(range(len_feat))\n",
      "        inds_one = inds_one[:4*(i+1)]\n",
      "        for j in inds_one:\n",
      "            feats[k, j] = 1\n",
      "        \n",
      "    return (labels, feats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def define_factor_types(num_vars, len_feat, edge_table):\n",
      "    \"\"\" Define factor types \n",
      "    \n",
      "        Args:\n",
      "            num_vars: number of variables in factor graph\n",
      "            len_feat: length of the feature vector\n",
      "            edge_table: edge table defines pair-wise node indeces\n",
      "        \n",
      "        Returns:\n",
      "            v_factor_types: list of all unary and pair-wise factor types\n",
      "    \"\"\"\n",
      "    n_stats = 2 # for binary status\n",
      "    v_factor_types = {}\n",
      "    n_edges = edge_table.shape[0]\n",
      "    \n",
      "    # unary factors\n",
      "    cards_u = np.array([n_stats], np.int32)\n",
      "    w_u = np.zeros(n_stats*len_feat)\n",
      "    for i in range(num_vars):\n",
      "        v_factor_types[i] = TableFactorType(i, cards_u, w_u)\n",
      "        \n",
      "    # pair-wise factors\n",
      "    cards_pw = np.array([n_stats, n_stats], np.int32)\n",
      "    w_pw = np.zeros(n_stats*n_stats)\n",
      "    for j in range(n_edges):\n",
      "        v_factor_types[j + num_vars] = TableFactorType(j + num_vars, cards_pw, w_pw)\n",
      "        \n",
      "    return v_factor_types"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_factor_graph_model(labels, feats, factor_types, edge_table, infer_alg = GRAPH_CUT):\n",
      "    \"\"\" Build factor graph model\n",
      "    \n",
      "        Args:\n",
      "            labels: matrix of labels [num_samples*len_label]\n",
      "            feats: maxtrix of feats [num_samples*len_feat]\n",
      "            factory_types: vectors of all factor types\n",
      "            edge_table: matrix of pairwised edges, each row is a pair of node indeces\n",
      "            infer_alg: inference algorithm (GRAPH_CUT)\n",
      "        Returns:\n",
      "            labels_fg: matrix of labels in factor graph format\n",
      "            feats_fg: matrix of features in factor graph format          \n",
      "    \"\"\"\n",
      "    \n",
      "    labels = labels.astype(np.int32)\n",
      "    num_samples = labels.shape[0]\n",
      "    num_vars = labels.shape[1]\n",
      "    num_edges = edge_table.shape[0]\n",
      "    n_stats = 2\n",
      "    \n",
      "    feats_fg = FactorGraphFeatures(num_samples)\n",
      "    labels_fg = FactorGraphLabels(num_samples)\n",
      "    \n",
      "    for i in range(num_samples):\n",
      "        cardinaities = np.array([n_stats]*num_vars, np.int32)\n",
      "        fg = FactorGraph(cardinaities)\n",
      "        \n",
      "        # add unary factors\n",
      "        for u in range(num_vars):\n",
      "            data_u = np.array(feats[i,:], np.float64)\n",
      "            inds_u = np.array([u], np.int32)\n",
      "            factor_u = Factor(factor_types[u], inds_u, data_u)\n",
      "            fg.add_factor(factor_u)\n",
      "            \n",
      "        # add pairwise factors\n",
      "        for v in range(num_edges):\n",
      "            data_p = np.array([1.0])\n",
      "            inds_p = np.array(edge_table[v, :], np.int32)\n",
      "            factor_p = Factor(factor_types[v + num_vars], inds_p, data_p)\n",
      "            fg.add_factor(factor_p)\n",
      "            \n",
      "        # add factor graph\n",
      "        feats_fg.add_sample(fg)\n",
      "        \n",
      "        # add corresponding label\n",
      "        loss_weights = np.array([1.0/num_vars]*num_vars)\n",
      "        fg_obs = FactorGraphObservation(labels[i,:], loss_weights)\n",
      "        labels_fg.add_label(fg_obs)\n",
      "\n",
      "    return (labels_fg, feats_fg)         "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def evaluation(labels_pr, labels_gt, model):\n",
      "    \"\"\" Evaluation\n",
      "    \n",
      "        Args:\n",
      "            labels_pr: predicted label\n",
      "            labels_gt: ground truth label\n",
      "            model: factor graph model\n",
      "        Returns:\n",
      "            ave_loss: average loss\n",
      "    \"\"\"\n",
      "    num_samples = labels_pr.get_num_labels()\n",
      "    acc_loss = 0.0\n",
      "    ave_loss = 0.0\n",
      "    for i in range(num_samples):\n",
      "        y_pred = labels_pr.get_label(i)\n",
      "        y_truth = labels_gt.get_label(i)\n",
      "        acc_loss = acc_loss + model.delta_loss(y_truth, y_pred)\n",
      "\n",
      "    ave_loss = acc_loss / num_samples\n",
      "    \n",
      "    return ave_loss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_inference(feats_fg, labels_fg, ind_sample, infer_type):\n",
      "    \"\"\" Test inference\n",
      "    \n",
      "        Args:\n",
      "            feats_fg: features for factor graph model\n",
      "            labels_fg: labels for factor graph model\n",
      "            ind_sample: sample id\n",
      "            infer_type: inference type\n",
      "            \n",
      "        Returns:\n",
      "            y_pred: predicted label\n",
      "            y_truth: ground truth label\n",
      "    \"\"\"\n",
      "    \n",
      "    # get a factor graph instance from test data\n",
      "    fg = feats_fg.get_sample(ind_sample)\n",
      "    fg.compute_energies()\n",
      "    fg.connect_components()\n",
      "\n",
      "    # create a MAP inference using graph cuts\n",
      "    infer_met = MAPInference(fg, infer_type)\n",
      "    infer_met.inference()\n",
      "\n",
      "    # get inference results\n",
      "    y_pred = infer_met.get_structured_outputs()\n",
      "    y_truth = FactorGraphObservation.obtain_from_generic(labels_fg.get_label(ind_sample))\n",
      "    \n",
      "    return y_pred, y_truth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Build Factor Graph Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_samples = 20\n",
      "len_label = 10\n",
      "len_feat = 40\n",
      "\n",
      "# generate synthetic dataset\n",
      "(labels_train, feats_train) = generate_data(num_samples, len_label, len_feat)\n",
      "\n",
      "# compute full-connected edge table\n",
      "full = np.vstack([x for x in itertools.combinations(range(len_label), 2)])\n",
      "\n",
      "# define factor types\n",
      "factor_types = define_factor_types(len_label, len_feat, full)\n",
      "\n",
      "# create features and labels for factor graph mode\n",
      "(labels_fg, feats_fg) = build_factor_graph_model(labels_train, feats_train, factor_types, full, GRAPH_CUT)\n",
      "\n",
      "# create model and register factor types\n",
      "model = FactorGraphModel(feats_fg, labels_fg, GRAPH_CUT)\n",
      "\n",
      "for i in range(len(factor_types)):\n",
      "    model.add_factor_type(factor_types[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the 3rd parameter is do_weighted_averaging, by turning this on, \n",
      "# a possibly faster convergence rate may be achieved.\n",
      "# the 4th parameter controls outputs of verbose training information\n",
      "sgd = StochasticSOSVM(model, labels_fg, True, True)\n",
      "\n",
      "sgd.set_num_iter(150)\n",
      "sgd.set_lambda(0.0001)\n",
      "    \n",
      "# train\n",
      "t0 = time.time()\n",
      "sgd.train()\n",
      "t1 = time.time()\n",
      "    \n",
      "w_sgd = sgd.get_w()\n",
      "    \n",
      "print \"SGD took\", t1 - t0, \"seconds.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Inference"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ind_sample = 1\n",
      "infer_type = GRAPH_CUT\n",
      "y_pred, y_truth = test_inference(feats_fg, labels_fg, ind_sample, infer_type)\n",
      "print y_pred.get_data()\n",
      "print y_truth.get_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# training error\n",
      "labels_pr = sgd.apply()\n",
      "ave_loss = evaluation(labels_pr, labels_fg, model)\n",
      "print('SGD: Average training error is %.4f' % ave_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# testing error\n",
      "num_test_samples = 10\n",
      "# generate synthetic testing dataset\n",
      "(labels_test, feats_test) = generate_data(num_test_samples, len_label, len_feat)\n",
      "# create features and labels for factor graph mode\n",
      "(labels_fg_test, feats_fg_test) = build_factor_graph_model(labels_test, feats_test, factor_types, full, GRAPH_CUT)\n",
      "# set features and labels to sgd\n",
      "sgd.set_features(feats_fg_test)\n",
      "sgd.set_labels(labels_fg_test)\n",
      "# test\n",
      "labels_pr = sgd.apply()\n",
      "ave_loss = evaluation(labels_pr, labels_fg_test, model)\n",
      "print('SGD: Average testing error is %.4f' % ave_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Experiment 3: Multilabel classification with Real-world Dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_data(fname):\n",
      "    \"\"\" Load svm format data\n",
      "    \"\"\"\n",
      "    data_file = open(fname)\n",
      "    lines = data_file.readlines()\n",
      "    n_samples = len(lines)\n",
      "    n_features = len(lines[0].split()) - 1\n",
      "    Y1 = []\n",
      "    X = []\n",
      "    for line in lines:\n",
      "        data = line.split()\n",
      "        Y1.append(map(int, data[0].split(\",\")))\n",
      "        feats = []\n",
      "        for feat in data[1:]:\n",
      "            feats.append(float(feat.split(\":\")[1]))\n",
      "        X.append(feats)\n",
      "    X = np.array(X)\n",
      "    n_classes = max(max(label) for label in Y1) + 1\n",
      "    Y = np.zeros((n_samples, n_classes), np.int32)\n",
      "    for i in range(n_samples):\n",
      "        for j in Y1[i]:\n",
      "            Y[i, j] = 1\n",
      "    return X, Y, n_samples, n_features, n_classes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load scene dataset\n",
      "fname_train = '../../../data/multilabel/scene_train'\n",
      "fname_test = '../../../data/multilabel/scene_test'\n",
      "X_train, Y_train, num_samples_train, len_feat, len_label = load_data(fname_train)\n",
      "X_test, Y_test, num_samples_test, len_feat, len_label = load_data(fname_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.1 Tree max-product inference"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Build Factor Graph Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tree structure is defined by edge table\n",
      "tree = np.zeros((5,2), np.int32)\n",
      "tree[0,:] = [0, 2]\n",
      "tree[1,:] = [0, 3]\n",
      "tree[2,:] = [1, 4]\n",
      "tree[3,:] = [4, 5]\n",
      "tree[4,:] = [2, 5]\n",
      "\n",
      "# define factor types\n",
      "factor_types = define_factor_types(len_label, len_feat, tree)\n",
      "\n",
      "# create features and labels for factor graph mode\n",
      "(labels_fg_train, feats_fg_train) = build_factor_graph_model(Y_train, X_train, factor_types, tree, TREE_MAX_PROD)\n",
      "\n",
      "# create model and register factor types\n",
      "model_tree = FactorGraphModel(feats_fg_train, labels_fg_train, TREE_MAX_PROD)\n",
      "\n",
      "for i in range(len(factor_types)):\n",
      "    model_tree.add_factor_type(factor_types[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infer_type = TREE_MAX_PROD\n",
      "for i in range(10):\n",
      "    y_pred, y_truth = test_inference(feats_fg_train, labels_fg_train, i, infer_type)\n",
      "    print y_pred.get_data()\n",
      "    print y_truth.get_data()\n",
      "    print '----------------'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the 3rd parameter is do_weighted_averaging, by turning this on, \n",
      "# a possibly faster convergence rate may be achieved.\n",
      "# the 4th parameter controls outputs of verbose training information\n",
      "sgd = StochasticSOSVM(model_tree, labels_fg_train, True, True)\n",
      "\n",
      "sgd.set_num_iter(200)\n",
      "sgd.set_lambda(0.0001)\n",
      "    \n",
      "# train\n",
      "t0 = time.time()\n",
      "sgd.train()\n",
      "t1 = time.time()\n",
      "    \n",
      "w_sgd = sgd.get_w()\n",
      "    \n",
      "print \"SGD took\", t1 - t0, \"seconds.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
      "\n",
      "primal_sgd = sgd.get_helper().get_primal_values()\n",
      "dual_sgd = sgd.get_helper().get_dual_values()\n",
      "\n",
      "len_iter = min(primal_sgd.size, dual_sgd.size)\n",
      "primal_sgd = primal_sgd[1:len_iter]\n",
      "dual_sgd = dual_sgd[1:len_iter]\n",
      "\n",
      "# plot duality gaps\n",
      "xs = range(dual_sgd.size)\n",
      "axes[0].plot(xs, (primal_sgd-dual_sgd), label='duality gap')\n",
      "axes[0].set_xlabel('iteration')\n",
      "axes[0].set_ylabel('duality gap')\n",
      "axes[0].legend(loc=1)\n",
      "axes[0].set_title('duality gaps');\n",
      "axes[0].grid(True)\n",
      "\n",
      "# plot primal and dual values\n",
      "xs = range(dual_sgd.size-1)\n",
      "axes[1].plot(xs, primal_sgd[1:], label='primal')\n",
      "axes[1].plot(xs, dual_sgd[1:], label='dual')\n",
      "axes[1].set_xlabel('iteration')\n",
      "axes[1].set_ylabel('objective')\n",
      "axes[1].legend(loc=1)\n",
      "axes[1].set_title('primal vs dual');\n",
      "axes[1].grid(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.2 Graph-cuts inference"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Build Factor Graph Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# compute full-connected edge table\n",
      "full = np.vstack([x for x in itertools.combinations(range(len_label), 2)])\n",
      "\n",
      "# define factor types\n",
      "factor_types = define_factor_types(len_label, len_feat, full)\n",
      "\n",
      "# create features and labels for factor graph mode\n",
      "(labels_fg_train, feats_fg_train) = build_factor_graph_model(Y_train, X_train, factor_types, full, GRAPH_CUT)\n",
      "\n",
      "# create model and register factor types\n",
      "model_full = FactorGraphModel(feats_fg_train, labels_fg_train, GRAPH_CUT)\n",
      "\n",
      "for i in range(len(factor_types)):\n",
      "    model_full.add_factor_type(factor_types[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the 3rd parameter is do_weighted_averaging, by turning this on, \n",
      "# a possibly faster convergence rate may be achieved.\n",
      "# the 4th parameter controls outputs of verbose training information\n",
      "sgd = StochasticSOSVM(model_full, labels_fg_train, True, True)\n",
      "\n",
      "sgd.set_num_iter(200)\n",
      "sgd.set_lambda(0.0001)\n",
      "    \n",
      "# train\n",
      "t0 = time.time()\n",
      "sgd.train()\n",
      "t1 = time.time()\n",
      "    \n",
      "w_sgd = sgd.get_w()\n",
      "    \n",
      "print \"SGD took\", t1 - t0, \"seconds.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
      "\n",
      "primal_sgd = sgd.get_helper().get_primal_values()\n",
      "dual_sgd = sgd.get_helper().get_dual_values()\n",
      "\n",
      "len_iter = min(primal_sgd.size, dual_sgd.size)\n",
      "primal_sgd = primal_sgd[1:len_iter]\n",
      "dual_sgd = dual_sgd[1:len_iter]\n",
      "\n",
      "# plot duality gaps\n",
      "xs = range(dual_sgd.size)\n",
      "axes[0].plot(xs, (primal_sgd-dual_sgd), label='duality gap')\n",
      "axes[0].set_xlabel('iteration')\n",
      "axes[0].set_ylabel('duality gap')\n",
      "axes[0].legend(loc=1)\n",
      "axes[0].set_title('duality gaps');\n",
      "axes[0].grid(True)\n",
      "\n",
      "# plot primal and dual values\n",
      "xs = range(dual_sgd.size-1)\n",
      "axes[1].plot(xs, primal_sgd[1:], label='primal')\n",
      "axes[1].plot(xs, dual_sgd[1:], label='dual')\n",
      "axes[1].set_xlabel('iteration')\n",
      "axes[1].set_ylabel('objective')\n",
      "axes[1].legend(loc=1)\n",
      "axes[1].set_title('primal vs dual');\n",
      "axes[1].grid(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create bundle method SOSVM, there are few variants can be chosen\n",
      "# BMRM, Proximal Point BMRM, Proximal Point P-BMRM, NCBM\n",
      "# usually the default one i.e. BMRM is good enough\n",
      "# lambda is set to 1e-2\n",
      "bmrm = DualLibQPBMSOSVM(model_full, labels_fg_train, 0.01)\n",
      "\n",
      "bmrm.set_TolAbs(20.0)\n",
      "bmrm.set_verbose(True)\n",
      "bmrm.set_store_train_info(True)\n",
      "    \n",
      "# train\n",
      "t0 = time.time()\n",
      "bmrm.train()\n",
      "t1 = time.time()\n",
      "\n",
      "w_bmrm = bmrm.get_w()\n",
      "\n",
      "print \"BMRM took\", t1 - t0, \"seconds.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
      "\n",
      "primal_bmrm = bmrm.get_helper().get_primal_values()\n",
      "dual_bmrm = bmrm.get_result().get_hist_Fd_vector()\n",
      "\n",
      "len_iter = min(primal_bmrm.size, dual_bmrm.size)\n",
      "primal_bmrm = primal_bmrm[1:len_iter]\n",
      "dual_bmrm = dual_bmrm[1:len_iter]\n",
      "\n",
      "# plot duality gaps\n",
      "xs = range(dual_bmrm.size)\n",
      "axes[0].plot(xs, (primal_bmrm-dual_bmrm), label='duality gap')\n",
      "axes[0].set_xlabel('iteration')\n",
      "axes[0].set_ylabel('duality gap')\n",
      "axes[0].legend(loc=1)\n",
      "axes[0].set_title('duality gaps');\n",
      "axes[0].grid(True)\n",
      "\n",
      "# plot primal and dual values\n",
      "xs = range(dual_bmrm.size-1)\n",
      "axes[1].plot(xs, primal_bmrm[1:], label='primal')\n",
      "axes[1].plot(xs, dual_bmrm[1:], label='dual')\n",
      "axes[1].set_xlabel('iteration')\n",
      "axes[1].set_ylabel('objective')\n",
      "axes[1].legend(loc=1)\n",
      "axes[1].set_title('primal vs dual');\n",
      "axes[1].grid(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "infer_type = GRAPH_CUT\n",
      "for i in range(10):\n",
      "    y_pred, y_truth = test_inference(feats_fg_train, labels_fg_train, i, infer_type)\n",
      "    print y_pred.get_data()\n",
      "    print y_truth.get_data()\n",
      "    print '----------------'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# training error (BMRM)\n",
      "labels_pr = bmrm.apply()\n",
      "ave_loss = evaluation(labels_pr, labels_fg_train, model)\n",
      "print('BMRM: Average training error is %.4f' % ave_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# training error (SGD)\n",
      "labels_pr = sgd.apply()\n",
      "ave_loss = evaluation(labels_pr, labels_fg_train, model_full)\n",
      "print('SGD: Average training error is %.4f' % ave_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create features and labels for factor graph mode\n",
      "(labels_fg_test, feats_fg_test) = build_factor_graph_model(Y_test, X_test, factor_types, full, GRAPH_CUT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# testing error (BMRM)\n",
      "# set features and labels to sgd\n",
      "bmrm.set_features(feats_fg_test)\n",
      "bmrm.set_labels(labels_fg_test)\n",
      "# test\n",
      "labels_pr = bmrm.apply()\n",
      "ave_loss = evaluation(labels_pr, labels_fg_test, model)\n",
      "print('BMRM: Average testing error is %.4f' % ave_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# testing error (SGD)\n",
      "# set features and labels to sgd\n",
      "sgd.set_features(feats_fg_test)\n",
      "sgd.set_labels(labels_fg_test)\n",
      "# test\n",
      "labels_pr = sgd.apply()\n",
      "ave_loss = evaluation(labels_pr, labels_fg_test, model_full)\n",
      "print('SGD: Average testing error is %.4f' % ave_loss)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[1] Finley, Thomas, and Thorsten Joachims. \"Training structural SVMs when exact inference is intractable.\" Proceedings of the 25th international conference on Machine learning. ACM, 2008."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}